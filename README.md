```markdown
# Early Stage Diabetes Risk Prediction Model

## Project Overview
This project implements a comprehensive machine learning pipeline for predicting early-stage diabetes risk using clinical symptoms. The model utilizes logistic regression with advanced statistical validation techniques to provide interpretable and reliable predictions. This project is based on the analysis performed in the `early-stage-diabetes-risk-prediction.ipynb` notebook.

## Dataset
- **Source**: The dataset used is `diabetes_data_upload.csv`, which is part of the "Early Diabetes Classification" dataset available on Kaggle. It can be found at: [https://www.kaggle.com/datasets/andrewmvd/early-diabetes-classification](https://www.kaggle.com/datasets/andrewmvd/early-diabetes-classification)
- **Samples**: 520 patients
- **Description**: The dataset contains information on 520 patients, including 16 clinical symptoms and demographic data, aimed at predicting the early presence of diabetes.

## Features
The model uses the following 18 features (16 original + 2 derived):
- Age (Numeric)
- Gender (Categorical: Male/Female, encoded as 0/1)
- Polyuria (Binary: Yes/No, encoded as 1/0)
- Polydipsia (Binary: Yes/No, encoded as 1/0)
- Sudden weight loss (Binary: Yes/No, encoded as 1/0)
- Weakness (Binary: Yes/No, encoded as 1/0)
- Polyphagia (Binary: Yes/No, encoded as 1/0)
- Genital thrush (Binary: Yes/No, encoded as 1/0)
- Visual blurring (Binary: Yes/No, encoded as 1/0)
- Itching (Binary: Yes/No, encoded as 1/0)
- Irritability (Binary: Yes/No, encoded as 1/0)
- Delayed healing (Binary: Yes/No, encoded as 1/0)
- Partial paresis (Binary: Yes/No, encoded as 1/0)
- Muscle stiffness (Binary: Yes/No, encoded as 1/0)
- Alopecia (Binary: Yes/No, encoded as 1/0)
- Obesity (Binary: Yes/No, encoded as 1/0)
- `symptom_count` (Numeric, derived): Sum of the 14 binary symptom features (Polyuria to Obesity).
- `age_obesity_interaction` (Numeric, derived): Product of Age and Obesity (encoded).

## Target Variable
- **Class**: Early-stage diabetes (Binary classification: Positive/Negative, encoded as 1/0).

## Model
- **Algorithm**: Logistic Regression
- **Preprocessing**:
    - Data Cleaning (handling outliers, consistent column names)
    - Categorical to Numeric Conversion
    - Feature Scaling (StandardScaler)
    - Handling Class Imbalance (SMOTE - Synthetic Minority Over-sampling Technique)
- **Model Persistence**: The trained pipeline, scaler, and model coefficients are saved using `joblib`:
    - `diabetes_predictor_v2.pkl` (the full scikit-learn pipeline)
    - `diabetes_scaler.pkl` (the StandardScaler object)
    - `diabetes_model_coefficients.pkl` (intercept, coefficients, and feature names for interpretability)

## Evaluation Metrics
The model's performance is evaluated using the following metrics:
- ROC AUC Score
- Sensitivity (True Positive Rate, Recall)
- Specificity (True Negative Rate)
- Positive Predictive Value (PPV, Precision)
- Negative Predictive Value (NPV)
- F1-Score
- Confusion Matrix
- Classification Report
- Log-Likelihood, AIC (Akaike Information Criterion), BIC (Bayesian Information Criterion)
- Advanced Cross-Validation Techniques (Repeated Stratified K-Fold, Nested CV, Learning Curves, Bootstrap Validation)

## Results
The model demonstrates excellent performance in predicting early-stage diabetes risk:
- **Cross-validation ROC AUC (5-Fold Stratified CV on resampled data)**: 0.9807 Â± 0.0101
- **Test Set Performance**:
    - ROC AUC Score: 0.9932
    - Sensitivity (Recall): 0.9531
    - Specificity: 0.9844
    - Precision (PPV): 0.9839
    - NPV: 0.9545
    - Accuracy: 0.97 (from test set confusion matrix: (63+61)/128)
- **Model Interpretability**:
    - Log-Likelihood: -14.8861
    - AIC: 67.7722
    - BIC: 121.9608
- The notebook also includes detailed coefficient analysis, odds ratios, and feature stability analysis. SHAP analysis was initialized but detailed results/plots are not present in the final notebook state.

## How to Use
The trained model can be loaded and used to make predictions on new patient data.

### 1. Load Necessary Files
Ensure you have the following files in your working directory (these are generated by the notebook `early-stage-diabetes-risk-prediction.ipynb`):
- `diabetes_predictor_v2.pkl`
- `diabetes_scaler.pkl`
- `diabetes_model_coefficients.pkl`

### 2. Prediction Code
```python
import pandas as pd
import numpy as np
import joblib

# --- Load Model and Helper Objects ---
# The main pipeline for prediction
pipeline = joblib.load('diabetes_predictor_v2.pkl')
# Scaler and coefficients are loaded for the full predict_diabetes_status function,
# particularly for logit calculation and feature contribution analysis.
saved_scaler = joblib.load('diabetes_scaler.pkl')
model_coefficients = joblib.load('diabetes_model_coefficients.pkl')

# --- Helper Functions (from notebook) ---
def calculate_odds(probability):
    # Calculate odds from probability: p/(1-p)
    # Added epsilon for stability if probability is exactly 1.0
    return probability / (1 - probability + 1e-15)

# --- Optimal Thresholds (derived from notebook analysis) ---
# These values are based on Youden's J statistic for ROC and F1-optimal for PR curve.
# For a simple classification, a standard 0.5 threshold can also be used.
optimal_threshold_roc = 0.3666  # Example value from notebook
optimal_threshold_pr = 0.3666   # Example value from notebook

# --- Main Prediction Function (adapted from notebook for clarity) ---
def predict_diabetes_status(age, gender, polyuria, polydipsia, sudden_weight_loss,
                           weakness, polyphagia, genital_thrush, visual_blurring,
                           itching, irritability, delayed_healing, partial_paresis,
                           muscle_stiffness, alopecia, obesity,
                           symptom_count, age_obesity_interaction):

    # Define the order of features as used in the training of the pipeline
    feature_names = ['age', 'gender', 'polyuria', 'polydipsia', 'sudden weight loss',
                     'weakness', 'polyphagia', 'genital thrush', 'visual blurring',
                     'itching', 'irritability', 'delayed healing', 'partial paresis',
                     'muscle stiffness', 'alopecia', 'obesity', 'symptom_count',
                     'age_obesity_interaction']

    input_data_dict = {
        'age': age, 'gender': gender, 'polyuria': polyuria, 'polydipsia': polydipsia,
        'sudden weight loss': sudden_weight_loss, 'weakness': weakness, 'polyphagia': polyphagia,
        'genital thrush': genital_thrush, 'visual blurring': visual_blurring, 'itching': itching,
        'irritability': irritability, 'delayed healing': delayed_healing, 'partial paresis': partial_paresis,
        'muscle stiffness': muscle_stiffness, 'alopecia': alopecia, 'obesity': obesity,
        'symptom_count': symptom_count, 'age_obesity_interaction': age_obesity_interaction
    }

    input_df = pd.DataFrame([input_data_dict], columns=feature_names)

    # Get probability of positive class (diabetes) using the pipeline
    probability_positive = pipeline.predict_proba(input_df)[0][1]
    odds_positive = calculate_odds(probability_positive)

    # Calculate logit using the model coefficients (for interpretability)
    # Note: The pipeline handles scaling internally for predict_proba.
    # For logit calculation with raw coefficients, data must be explicitly scaled.
    input_scaled_df = pd.DataFrame(saved_scaler.transform(input_df), columns=feature_names)
    logit_calculated = model_coefficients['intercept'] + np.sum(model_coefficients['coefficients'] * input_scaled_df.iloc[0].values)

    # Feature contributions to the logit
    feature_contributions = {}
    for i, feature in enumerate(feature_names):
        contribution = model_coefficients['coefficients'][i] * input_scaled_df.iloc[0, i]
        feature_contributions[feature] = contribution

    sorted_contributions = sorted(feature_contributions.items(), key=lambda x: abs(x[1]), reverse=True)

    # Classifications based on different thresholds
    classifications = {
        'default_0.5_threshold': 'High Risk (Positive)' if probability_positive > 0.5 else 'Low Risk (Negative)',
        'roc_optimal_threshold': 'High Risk (Positive)' if probability_positive > optimal_threshold_roc else 'Low Risk (Negative)',
        'pr_optimal_threshold': 'High Risk (Positive)' if probability_positive > optimal_threshold_pr else 'Low Risk (Negative)'
    }

    return {
        'input_features': input_df.iloc[0].to_dict(),
        'probability_positive_percent': round(probability_positive * 100, 2),
        'odds_positive': round(odds_positive, 2),
        'logit_calculated': round(logit_calculated, 4),
        'classifications': classifications,
        'top_5_contributors_to_logit': [
            {'feature': f, 'contribution': round(c, 4)} for f, c in sorted_contributions[:5]
        ]
    }

# Example Usage:
# Define input values for a patient (same as notebook example)
patient_age = 45
patient_gender = 0 # Male
patient_polyuria = 1 # Yes
patient_polydipsia = 1 # Yes
patient_sudden_weight_loss = 0 # No
patient_weakness = 1 # Yes
patient_polyphagia = 0 # No
patient_genital_thrush = 0 # No
patient_visual_blurring = 1 # Yes
patient_itching = 0 # No
patient_irritability = 0 # No
patient_delayed_healing = 0 # No
patient_partial_paresis = 0 # No
patient_muscle_stiffness = 0 # No
patient_alopecia = 1 # Yes
patient_obesity = 0 # No

# Calculate derived features for the example
# These are the 14 binary symptoms used for 'symptom_count'
binary_symptom_values_for_example = [
    patient_polyuria, patient_polydipsia, patient_sudden_weight_loss, patient_weakness,
    patient_polyphagia, patient_genital_thrush, patient_visual_blurring, patient_itching,
    patient_irritability, patient_delayed_healing, patient_partial_paresis,
    patient_muscle_stiffness, patient_alopecia, patient_obesity
]
patient_symptom_count = sum(binary_symptom_values_for_example)
patient_age_obesity_interaction = patient_age * patient_obesity

# Make a prediction
prediction_example = predict_diabetes_status(
    age=patient_age, gender=patient_gender, polyuria=patient_polyuria,
    polydipsia=patient_polydipsia, sudden_weight_loss=patient_sudden_weight_loss,
    weakness=patient_weakness, polyphagia=patient_polyphagia,
    genital_thrush=patient_genital_thrush, visual_blurring=patient_visual_blurring,
    itching=patient_itching, irritability=patient_irritability,
    delayed_healing=patient_delayed_healing, partial_paresis=patient_partial_paresis,
    muscle_stiffness=patient_muscle_stiffness, alopecia=patient_alopecia,
    obesity=patient_obesity,
    symptom_count=patient_symptom_count,
    age_obesity_interaction=patient_age_obesity_interaction
)

print("--- Example Patient Prediction ---")
# print(f"Input Features: {prediction_example['input_features']}") # This can be verbose
print(f"Probability of Diabetes (Positive Class): {prediction_example['probability_positive_percent']}%")
print(f"Odds of Diabetes (Positive Class): {prediction_example['odds_positive']}")
print(f"Calculated Logit: {prediction_example['logit_calculated']}")
print(f"Classifications based on various thresholds: {prediction_example['classifications']}")
print("\nTop 5 Contributors to Logit (Prediction Score):")
for item in prediction_example['top_5_contributors_to_logit']:
    print(f"  - Feature: {item['feature']}, Contribution: {item['contribution']}")

```

## Model Limitations
1.  **Self-Reported Data**: The model is based on symptoms that may be self-reported, which can introduce bias or inaccuracies.
2.  **Focus on Early Stage**: The prediction is specifically for early-stage diabetes and may not generalize well to other stages or types of diabetes.
3.  **Feature Set**: Performance is limited to the 18 features (16 original + 2 derived) used in this dataset. Other unobserved factors could influence diabetes risk.
4.  **External Validation**: The model requires validation on new, diverse datasets and populations to confirm its broader applicability and robustness.
5.  **SMOTE**: Class imbalance was addressed using SMOTE. While effective, synthetic data generation can sometimes influence model behavior on real-world, naturally distributed data.

## Dependencies
The project relies on the following Python libraries:
- pandas (for data manipulation)
- numpy (for numerical operations)
- scikit-learn (for machine learning tasks: model, metrics, preprocessing, pipeline)
- imblearn (specifically SMOTE for handling class imbalance)
- joblib (for saving and loading the model)
- seaborn (for visualizations)
- matplotlib (for plotting)
- shap (for model interpretability, used in the notebook for analysis)

## Author
- Ahmed Yassin Mohammed

## Date
- May 31, 2025 (as per notebook metadata)

## Version
- 2.0 (as per notebook metadata)
```
